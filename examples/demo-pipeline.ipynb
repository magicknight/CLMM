{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a WL mass using `clmm`\n",
    "\n",
    "_the LSST-DESC CLMM team_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import clmm\n",
    "#from clmm import modeling as mod\n",
    "import os, sys\n",
    "sys.path.append('%s/support'%os.path.dirname(os.path.realpath(__file__)))\n",
    "import mock_data as mock\n",
    "from numpy import random\n",
    "from scipy import optimize as spo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a true cosmology\n",
    "# NB: need to cclify the astropy cosmology for generating the mock data (depends on modeling.py). \n",
    "# However, this is the astropy cosmology object that will need to be used on the data side, \n",
    "# profileaveraging.py (data side)\n",
    "\n",
    "mock_cosmo = FlatLambdaCDM(H0=70, Om0=0.27, Ob0=0.045)\n",
    "# cclify allows access to the cosmo parameter the CCL way, but it is NOT a CCL cosmology object,\n",
    "# but simply a dictionary\n",
    "mock_cosmo_ccl = clmm.cclify_astropy_cosmo(mock_cosmo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define toy cluster parameters\n",
    "\n",
    "config = {}\n",
    "config['cosmo'] = mock_cosmo_ccl\n",
    "config['cluster_id'] = \"Awesome_cluster\"\n",
    "config['cluster_m'] = 1.e15\n",
    "config['cluster_z'] = 0.3\n",
    "config['src_z'] = 0.8\n",
    "config['concentration'] = 4\n",
    "config['ngals'] = 10000\n",
    "config['Delta'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make mock data object\n",
    "\n",
    "ideal_data = mock.MockData(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate catalog of galaxy cluster\n",
    "\n",
    "ideal_data.generate() # single source plane, no shape noise, no redshift error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a clmm.GalaxyCluster object\n",
    "# NB: mock data puts galaxy clusters in (0,0)\n",
    "cluster_ra = 0.0\n",
    "cluster_dec = 0.0\n",
    "gc_object = clmm.GalaxyCluster(config['cluster_id'], cluster_ra, cluster_dec, \n",
    "                               config['cluster_z'], ideal_data.catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the clmm.GalaxyCluster object\n",
    "\n",
    "gc_object.save('mock_GC.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a clmm.GalaxyCluster object\n",
    "\n",
    "cl = clmm.load_cluster('mock_GC.pkl')\n",
    "\n",
    "ra_l = cl.ra\n",
    "dec_l = cl.dec\n",
    "z = cl.z\n",
    "e1 = cl.galcat['e1']\n",
    "e2 = cl.galcat['e2']\n",
    "ra_s = cl.galcat['ra']\n",
    "dec_s = cl.galcat['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(ra_s, dec_s, marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangential shear, cross shear for each source galaxy in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(theta, g_t, g_x) = cl.compute_shear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(theta, g_t, '.')\n",
    "plt.ylabel(\"reduced shear\")\n",
    "plt.xlabel(\"angular distance [deg?]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the binned profile\n",
    "\n",
    "Using 2 different binnings to highlight the impact on the reconstructed mass when doing naive fitting (not accounting for the binning in the model estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bins\n",
    "bin_edges1 = clmm.make_bins(0.01, 3.7, 50)\n",
    "bin_edges2 = clmm.make_bins(0.01, 3.7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = cl.make_shear_profile(\"Mpc\", cosmo=mock_cosmo, cosmo_object_type='astropy', \n",
    "                             bins=bin_edges1)\n",
    "res2 = cl.make_shear_profile(\"Mpc\", cosmo=mock_cosmo, cosmo_object_type='astropy', \n",
    "                             bins=bin_edges2)\n",
    "\n",
    "plt.loglog(res1['radius'], res1['gt'], '.', label='50 bins')\n",
    "plt.loglog(res2['radius'], res2['gt'], '+', markersize=15, label='10 bins')\n",
    "plt.legend()\n",
    "gt_profile1 = res1['gt']\n",
    "r1 = res1['radius']\n",
    "\n",
    "gt_profile2 = res2['gt']\n",
    "r2 = res2['radius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now the galaxy cluster as a profile attribute\n",
    "cl.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct model\n",
    "\n",
    "Simply estimating the model at the bin location. In that case, the mass reconstruction is dependent on the binning. Future developement would be to take the average of the model inside the bin instead, which should solve this issue for this set of ideal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select density profile parametrization and parameter values\n",
    "def nfw_to_shear_profile1(logm):\n",
    "    m = 10.**logm\n",
    "    gt_model = clmm.predict_reduced_tangential_shear(r1, m, config['concentration'], config['cluster_z'], \n",
    "                                                    config['src_z'], config['cosmo'], \n",
    "                                        Delta=200, halo_profile_parameterization='nfw')\n",
    "    return sum(gt_model - gt_profile1) **2\n",
    "\n",
    "def nfw_to_shear_profile2(logm):\n",
    "    m = 10.**logm\n",
    "    gt_model = clmm.predict_reduced_tangential_shear(r2, m, config['concentration'], config['cluster_z'], \n",
    "                                                    config['src_z'], config['cosmo'], \n",
    "                                        Delta=200, halo_profile_parameterization='nfw')\n",
    "    return sum(gt_model - gt_profile2) **2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit for mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize to find the best-fit mass\n",
    "\n",
    "logm_0 = random.uniform(13., 17., 1)[0]\n",
    "logm_est1 = spo.minimize(nfw_to_shear_profile1, logm_0).x\n",
    "logm_est2 = spo.minimize(nfw_to_shear_profile2, logm_0).x\n",
    "m_est1 = 10.**logm_est1\n",
    "m_est2 = 10.**logm_est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est1, m_est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rr = np.logspace(-2,np.log10(5),100)\n",
    "gt_model1 = clmm.predict_reduced_tangential_shear(rr, m_est1, config['concentration'], config['cluster_z'], \n",
    "                                                    config['src_z'], config['cosmo'], \n",
    "                                        Delta=200, halo_profile_parameterization='nfw')\n",
    "\n",
    "gt_model2 = clmm.predict_reduced_tangential_shear(rr, m_est2, config['concentration'], config['cluster_z'], \n",
    "                                                    config['src_z'], config['cosmo'], \n",
    "                                        Delta=200, halo_profile_parameterization='nfw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(r1, gt_profile1, label='mock data, M_input = %.3e Msun'%config['cluster_m'])\n",
    "plt.plot(rr, gt_model1, label = 'best fit model, M_fit=%.3e'%m_est1, color='orange')\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('R [Mpc]')\n",
    "plt.ylabel('reduced tangential shear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(r2, gt_profile2, label='mock data, M_input = %.3e Msun'%config['cluster_m'])\n",
    "plt.plot(rr, gt_model2, label = 'best fit model, M_fit=%.3e'%m_est2, color='orange')\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('R [Mpc]')\n",
    "plt.ylabel('reduced tangential shear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
